{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from tensorflow import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import interpolate\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pandas import to_numeric\n",
    "from hmmlearn import hmm\n",
    "\n",
    "def create_time_features(data):\n",
    "    # Assume 'cpu_data' is your dataframe and 'datetime' is the column with datetime values\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'])  # Ensure it's a datetime type\n",
    "    data['hour'] = data['datetime'].dt.hour\n",
    "    data['day_of_week'] = data['datetime'].dt.dayofweek\n",
    "    data['month'] = data['datetime'].dt.month\n",
    "    data['day_of_month'] = data['datetime'].dt.day\n",
    "    data['is_weekend'] = data['datetime'].dt.weekday >= 5  # True for Saturday and Sunday\n",
    "    return data\n",
    "\n",
    "# Define a function to create lagged features\n",
    "def create_additional_features(df, target_col, lags):\n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)\n",
    "    df['cpu_change'] = df['cpu_usage'].diff() # Change in CPU usage\n",
    "    df['moving_avg'] = df['cpu_usage'].rolling(window=10).mean() # 10-minute moving average\n",
    "    return df\n",
    "\n",
    "cpu_data = pd.read_csv('../Utilities\\csv/cpu_usage_data_test.csv')\n",
    "# Convert 'datetime' column to datetime objects\n",
    "cpu_data['datetime'] = pd.to_datetime(cpu_data['datetime'])\n",
    "\n",
    "# Set 'datetime' as the index\n",
    "cpu_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# Resample to 1-minute intervals and interpolate\n",
    "cpu_data = cpu_data.resample('1T').interpolate(method='linear')\n",
    "cpu_data.reset_index(inplace=True)\n",
    "if 'machine_id' in cpu_data.columns:\n",
    "    cpu_data['machine_id'] = pd.Categorical(cpu_data['machine_id']).codes + 1\n",
    "else:\n",
    "    cpu_data['machine_id'] = 1\n",
    "cpu_data = create_time_features(cpu_data)\n",
    "lags = [5, 10, 60]\n",
    "cpu_data = create_additional_features(cpu_data, 'cpu_usage', lags)\n",
    "\n",
    "# Drop any rows with NaN values that were created due to shifting\n",
    "cpu_data.dropna(inplace=True)\n",
    "\n",
    "column_to_move = cpu_data.pop('cpu_usage')\n",
    "cpu_data.insert(1, 'cpu_usage', column_to_move)\n",
    "all_features_no_timestamp = cpu_data.columns[1:len(cpu_data.columns)]\n",
    "# Extract the relevant features from your dataset for the HMM\n",
    "features_for_hmm = cpu_data[all_features_no_timestamp].values\n",
    "\n",
    "# Define and fit the HMM model\n",
    "num_states = 10  # You can adjust this based on the nature of the data\n",
    "model = hmm.GaussianHMM(n_components=num_states, covariance_type=\"full\", n_iter=1000)\n",
    "\n",
    "# Fit the HMM model to the features\n",
    "model.fit(features_for_hmm)\n",
    "\n",
    "# Predict hidden states for each time step\n",
    "hidden_states = model.predict(features_for_hmm)\n",
    "\n",
    "cpu_data['hidden_state'] = hidden_states\n",
    "\n",
    "cpu_data.head\n",
    "\n",
    "# Initialize scalers\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "# Window size (e.g., past 60 time steps) and prediction horizon (next 10 timesteps)\n",
    "window_size = 60\n",
    "prediction_horizon = 10\n",
    "\n",
    "# Function to generate LSTM sequences\n",
    "def create_lstm_sequences(group_data, window_size, prediction_horizon):\n",
    "    X, y = [], []\n",
    "    for i in range(len(group_data) - window_size - prediction_horizon + 1):\n",
    "        # Features are all columns except 'datetime', 'cpu_usage', and 'machine_id'\n",
    "        X.append(group_data.iloc[i:i + window_size].drop(columns=['datetime', 'cpu_usage', 'machine_id']).values)\n",
    "        # Target is the next 10 CPU usage values\n",
    "        y.append(group_data.iloc[i + window_size:i + window_size + prediction_horizon]['cpu_usage'].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "all_features_no_timestamp_cpu_usage = cpu_data.columns[2:len(cpu_data.columns)]\n",
    "# Scale features and target (fit on the entire dataset)\n",
    "cpu_data[all_features_no_timestamp_cpu_usage] = feature_scaler.fit_transform(cpu_data[all_features_no_timestamp_cpu_usage])\n",
    "cpu_data[[\"cpu_usage\"]] = target_scaler.fit_transform(cpu_data[[\"cpu_usage\"]])\n",
    "\n",
    "X_test, y_test = create_lstm_sequences(cpu_data, window_size, prediction_horizon)\n",
    "\n",
    "# Print the shapes of the final train/test data\n",
    "print(\"Train shapes:\", X_test.shape)\n",
    "print(\"Test shapes:\", y_test.shape)\n",
    "\n",
    "lstm_model = load_model('best_model_test.keras')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lstm_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions using the target scaler\n",
    "y_pred_unscaled = target_scaler.inverse_transform(y_pred)\n",
    "\n",
    "# If `y_test` also needs inverse transforming\n",
    "y_test_unscaled = target_scaler.inverse_transform(y_test)\n",
    "\n",
    "\n",
    "# Calculate MSE and RMSE\n",
    "mse_lstm = mean_squared_error(y_test_unscaled[0], y_pred_unscaled[0])\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "\n",
    "print(f\"RMSE: {rmse_lstm}, MSE: {mse_lstm}\")\n",
    "\n",
    "# Plotting Actual vs Predicted values\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_unscaled[0], label='Actual Values', color='blue', alpha=0.6)\n",
    "plt.plot(y_pred_unscaled[0], label='Predicted Values', color='orange', alpha=0.6)\n",
    "plt.title('Actual vs Predicted CPU Usage (10 Minutes)')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('CPU Usage')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "mse_lstm = mean_squared_error(y_test_unscaled, y_pred_unscaled)\n",
    "rmse_lstm = np.sqrt(mse_lstm)\n",
    "\n",
    "print(f\"RMSE: {rmse_lstm}, MSE: {mse_lstm}\")\n",
    "# Plotting Actual vs Predicted values\n",
    "y_test_rescaled_flat = y_test_unscaled.flatten()\n",
    "predictions_rescaled_flat = y_pred_unscaled.flatten()\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(y_test_rescaled_flat, label='Actual Values', color='blue', alpha=0.6)\n",
    "plt.plot(predictions_rescaled_flat, label='Predicted Values', color='orange', alpha=0.6)\n",
    "plt.title('Actual vs Predicted CPU Usage')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('CPU Usage')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
